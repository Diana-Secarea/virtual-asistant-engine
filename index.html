<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Virtual Assistant Engine</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles/main.css">
</head>
<body>
    <div class="stars" id="stars"></div>

   
    <div class="page active" id="homePage">
        <div class="navbar">
            <button class="login-btn" onclick="showPage('authPage')">
                <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2"></path>
                    <circle cx="12" cy="7" r="4"></circle>
                </svg>
                <span>Login</span>
            </button>
            <div class="icon-buttons">
                <button class="icon-btn" title="Voice Recognition" aria-disabled="true" disabled>
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path>
                        <path d="M19 10v2a7 7 0 0 1-14 0v-2"></path>
                        <line x1="12" y1="19" x2="12" y2="23"></line>
                        <line x1="8" y1="23" x2="16" y2="23"></line>
                    </svg>
                </button>
                <button class="icon-btn" title="Reminders">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <circle cx="12" cy="12" r="10"></circle>
                        <polyline points="12 6 12 12 16 14"></polyline>
                    </svg>
                </button>
                <button class="icon-btn" title="Questions">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <circle cx="12" cy="12" r="10"></circle>
                        <path d="M9.09 9a3 3 0 0 1 5.83 1c0 2-3 3-3 3"></path>
                        <line x1="12" y1="17" x2="12.01" y2="17"></line>
                    </svg>
                </button>
                <button class="icon-btn" title="Music Player">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M9 18V5l12-2v13"></path>
                        <circle cx="6" cy="18" r="3"></circle>
                        <circle cx="18" cy="16" r="3"></circle>
                    </svg>
                </button>
            </div>
        </div>
        <div class="main-content">
            <h1 class="main-title">Hello!</h1>
            <p class="subtitle">How can I help you?</p>
            <button class="start-btn" onclick="showPage('voiceAssistantPage')">Get Started</button>
            <div class="features-section">
                <p class="features-title">Voice Recognition Assistant</p>
                <p class="features-title" style="margin-top: 4px;">Features</p>
                <div class="scroll-indicator" onclick="showPage('featuresPage')">
                    <div class="arrow-down"></div>
                </div>
            </div>
        </div>
    </div>

    
    <div class="page" id="featuresPage">
        <div class="main-content">
            <h2 class="features-page-title">Voice Recognition Assistant Features</h2>
            <div class="features-list">
                <div class="feature-item">
                    <div class="feature-icon">üéôÔ∏è</div>
                    <div class="feature-text">Voice Recognition - Speak commands naturally using your microphone with advanced speech-to-text technology</div>
                </div>
                <div class="feature-item">
                    <div class="feature-icon">‚ùì</div>
                    <div class="feature-text">Intelligent Q&A - Get instant answers to various questions powered by AI</div>
                </div>
                <div class="feature-item">
                    <div class="feature-icon">‚è∞</div>
                    <div class="feature-text">Smart Reminders - Set and manage reminders with intuitive voice commands</div>
                </div>
                <div class="feature-item">
                    <div class="feature-icon">üéß</div>
                    <div class="feature-text">Music Control - Play, pause, and control your music library with voice commands</div>
                </div>
            </div>
        </div>
        <a class="continue-link" onclick="showPage('homePage')">‚Üê Back</a>
    </div>

    
    <div class="page" id="authPage">
        <div class="auth-container">
            <div class="user-icon-large">
                <svg width="48" height="48" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2"></path>
                    <circle cx="12" cy="7" r="4"></circle>
                </svg>
            </div>
            <h2 class="auth-title">Welcome</h2>
            <div class="auth-buttons">
                <button class="auth-btn" onclick="showPage('signUpPage')">Sign Up</button>
                <button class="auth-btn" onclick="showPage('signInPage')">Sign In</button>
            </div>
        </div>
        <a class="continue-link" onclick="showPage('homePage')">Continue without an account</a>
    </div>


    <div class="page" id="signUpPage">
        <div class="form-container">
            <div class="user-icon-large">
                <svg width="48" height="48" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M16 21v-2a4 4 0 0 0-4-4H5a4 4 0 0 0-4 4v2"></path>
                    <circle cx="8.5" cy="7" r="4"></circle>
                    <line x1="20" y1="8" x2="20" y2="14"></line>
                    <line x1="23" y1="11" x2="17" y2="11"></line>
                </svg>
            </div>
            <h2 class="auth-title">Create Account</h2>
            <form class="form-inputs" onsubmit="return false;">
                <div class="form-row">
                    <label class="form-label">Username</label>
                    <input type="text" class="form-input" placeholder="Enter your username" required>
                </div>
                <div class="form-row">
                    <label class="form-label">Email</label>
                    <input type="email" class="form-input" placeholder="Enter your email" required>
                </div>
                <div class="form-row">
                    <label class="form-label">Phone Number</label>
                    <input type="tel" class="form-input" placeholder="Enter your phone number" required>
                </div>
                <div class="form-row">
                    <label class="form-label">Password</label>
                    <input type="password" class="form-input" placeholder="Create a password" required>
                </div>
                <button class="next-btn" onclick="alert('Sign up functionality coming soon!')">Create Account</button>
            </form>
        </div>
        <a class="continue-link" onclick="showPage('homePage')">Continue without making an account</a>
    </div>

   
    <div class="page" id="signInPage">
        <div class="form-container">
            <div class="user-icon-large">
                <svg width="48" height="48" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2"></path>
                    <circle cx="12" cy="7" r="4"></circle>
                </svg>
            </div>
            <h2 class="auth-title">Welcome Back</h2>
            <form class="form-inputs" onsubmit="return false;">
                <div class="form-row">
                    <label class="form-label">Email</label>
                    <input type="email" class="form-input" placeholder="Enter your email" required>
                </div>
                <div class="form-row">
                    <label class="form-label">Password</label>
                    <input type="password" class="form-input" placeholder="Enter your password" required>
                </div>
                <a href="#" class="forgot-password" style="text-align: right; width: 100%; display: block;">Forgot password?</a>
                <button class="next-btn" onclick="alert('Sign in functionality coming soon!')">Sign In</button>
            </form>
        </div>
        <a class="continue-link" onclick="showPage('homePage')">Continue without an account</a>
    </div>

    
    <div class="page" id="voiceAssistantPage">
        <div class="voice-assistant-container">
            <h2 class="voice-title">Voice Assistant</h2>
            <div class="voice-canvas-wrapper">
                <canvas id="voiceCanvas"></canvas>
            </div>
            <div class="voice-status" id="voiceStatus" style="margin-top: 16px; color: var(--text-gray); font-size: 0.95rem; text-align: center; min-height: 24px;">
                Ready to capture audio...
            </div>
            <div class="voice-controls">
                <button class="voice-btn" id="startVoiceBtn" onclick="toggleVoiceRecognition()">Start Listening</button>
                <button class="voice-btn" onclick="showPage('homePage')">Back</button>
            </div>
        </div>
    </div>

    <script>
        // Create stars dynamically
        function createStars() {
            const starsContainer = document.getElementById('stars');
            const numStars = 50;
            
            for (let i = 0; i < numStars; i++) {
                const star = document.createElement('div');
                star.className = 'star';
                
                // Random size between 1-3px
                const size = Math.random() * 2 + 1;
                star.style.width = size + 'px';
                star.style.height = size + 'px';
                
                // Random position
                star.style.left = Math.random() * 100 + '%';
                star.style.top = Math.random() * 100 + '%';
                
                // Random animation duration
                star.style.animationDuration = (Math.random() * 2 + 1) + 's';
                
                starsContainer.appendChild(star);
            }
        }

        // this  is page navigation
        function showPage(pageId) {
            // Cleanup voice assistant when leaving the page
            const currentPage = document.querySelector('.page.active');
            if (currentPage && currentPage.id === 'voiceAssistantPage' && pageId !== 'voiceAssistantPage') {
                if (isListening) {
                    isListening = false;
                    stopMicrophoneCapture();
                    const btn = document.getElementById('startVoiceBtn');
                    if (btn) {
                        btn.textContent = 'Start Listening';
                        btn.classList.remove('active');
                    }
                }
                if (animationFrameId) {
                    cancelAnimationFrame(animationFrameId);
                    animationFrameId = null;
                }
            }
            
            // Hide all pages
            document.querySelectorAll('.page').forEach(page => {
                page.classList.remove('active');
            });
            
            // Show selected page
            document.getElementById(pageId).classList.add('active');
            
            // Initialize voice canvas if voice assistant page is shown
            if (pageId === 'voiceAssistantPage') {
                initVoiceCanvas();
            }
        }

        // 
        //
        // Flow:
        // 1. getUserMedia() -> Get microphone access
        // 2. MediaStreamSource -> Connect microphone to Web Audio API
        // 3. AnalyserNode -> Perform FFT analysis on audio data
        // 4. getByteFrequencyData() -> Get frequency data (0-255 per frequency bin)
        // 5. Canvas visualization -> Draw real-time audio visualization
        // ========================================================================
        
        // Canvas and animation variables
        let voiceCanvas, voiceCtx;
        let isListening = false;
        let animationFrameId;
        let time = 0;
        
        // Web Audio API variables
        let audioContext;
        let analyser;
        let microphone;
        let dataArray;
        let bufferLength;
        let mediaStream;

        function initVoiceCanvas() {
            voiceCanvas = document.getElementById('voiceCanvas');
            if (!voiceCanvas) return;
            
            voiceCtx = voiceCanvas.getContext('2d');
            
            // Set canvas size
            function resizeCanvas() {
                const rect = voiceCanvas.getBoundingClientRect();
                voiceCanvas.width = rect.width;
                voiceCanvas.height = rect.height;
            }
            
            resizeCanvas();
            
            // Handle window resize
            window.addEventListener('resize', resizeCanvas);
            
            // Start animation
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
            }
            animateVoiceCanvas();
        }

        async function startMicrophoneCapture() {
            try {
                // Request microphone access
                mediaStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                
                // Create Audio Context
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                // Create analyser node for FFT analysis
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 512; // FFT size (power of 2)
                analyser.smoothingTimeConstant = 0.8; // Smoothing for visualization
                
                // Connect microphone to analyser
                microphone = audioContext.createMediaStreamSource(mediaStream);
                microphone.connect(analyser);
                
                // Get frequency data array size
                bufferLength = analyser.frequencyBinCount;
                dataArray = new Uint8Array(bufferLength);
                
                // Update status
                const statusEl = document.getElementById('voiceStatus');
                if (statusEl) {
                    statusEl.textContent = '‚úÖ Microphone connected successfully!';
                    statusEl.style.color = '#4ade80';
                }
                
                console.log('Microphone capture started successfully');
                return true;
            } catch (error) {
                console.error('Error accessing microphone:', error);
                
                // Update status
                const statusEl = document.getElementById('voiceStatus');
                if (statusEl) {
                    statusEl.textContent = '‚ùå Microphone access denied. Please check permissions.';
                    statusEl.style.color = '#ef4444';
                }
                
                alert('Could not access microphone. Please check permissions.');
                return false;
            }
        }

        function stopMicrophoneCapture() {
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            
            if (microphone) {
                microphone.disconnect();
                microphone = null;
            }
            
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            analyser = null;
            dataArray = null;
            
            // Update status
            const statusEl = document.getElementById('voiceStatus');
            if (statusEl) {
                statusEl.textContent = 'Microphone stopped. Ready to capture audio...';
                statusEl.style.color = 'var(--text-gray)';
            }
            
            console.log('Microphone capture stopped');
        }

        function animateVoiceCanvas() {
            if (!voiceCanvas || !voiceCtx) return;
            
            const width = voiceCanvas.width;
            const height = voiceCanvas.height;
            const centerX = width / 2;
            const centerY = height / 2;
            
            // Clear canvas
            voiceCtx.fillStyle = 'rgba(0, 0, 0, 0.1)';
            voiceCtx.fillRect(0, 0, width, height);
            
            // Draw gradient background
            const gradient = voiceCtx.createRadialGradient(centerX, centerY, 0, centerX, centerY, Math.max(width, height) / 2);
            gradient.addColorStop(0, 'rgba(140, 10, 34, 0.3)');
            gradient.addColorStop(0.5, 'rgba(139, 0, 0, 0.2)');
            gradient.addColorStop(1, 'rgba(0, 0, 0, 0.5)');
            voiceCtx.fillStyle = gradient;
            voiceCtx.fillRect(0, 0, width, height);
            
            // Get audio data from FFT if listening
            let audioData = null;
            let averageVolume = 0;
            
            if (isListening && analyser && dataArray) {
                // Get frequency data (FFT result)
                analyser.getByteFrequencyData(dataArray);
                audioData = Array.from(dataArray);
                
                // Calculate average volume
                const sum = audioData.reduce((a, b) => a + b, 0);
                averageVolume = sum / audioData.length;
                
                // Update status display
                const statusEl = document.getElementById('voiceStatus');
                if (statusEl) {
                    const volumePercent = Math.round((averageVolume / 255) * 100);
                    const maxFreq = Math.max(...audioData);
                    const statusColor = volumePercent > 50 ? 'var(--accent-red)' : 'var(--text-white)';
                    statusEl.style.color = statusColor;
                    statusEl.textContent = `üé§ Listening... | Volume: ${volumePercent}% | Max Frequency: ${maxFreq}`;
                }
            }
            
            // Draw microphone icon in center with dynamic size based on volume
            const micSize = isListening ? 80 + (averageVolume / 255) * 40 : 60;
            drawMicrophone(centerX, centerY, micSize);
            
            // Draw sound waves with real audio data
            if (isListening && audioData) {
                drawRealTimeSoundWaves(centerX, centerY, width, height, audioData, averageVolume);
            }
            
            time += 0.05;
            animationFrameId = requestAnimationFrame(animateVoiceCanvas);
        }

        function drawMicrophone(x, y, size) {
            voiceCtx.save();
            
            // Microphone body
            const bodyWidth = size * 0.4;
            const bodyHeight = size * 0.6;
            const bodyX = x - bodyWidth / 2;
            const bodyY = y - bodyHeight / 2;
            
            // Outer glow
            const glowGradient = voiceCtx.createRadialGradient(x, y, 0, x, y, size);
            glowGradient.addColorStop(0, isListening ? 'rgba(140, 10, 34, 0.8)' : 'rgba(140, 10, 34, 0.4)');
            glowGradient.addColorStop(1, 'rgba(140, 10, 34, 0)');
            voiceCtx.fillStyle = glowGradient;
            voiceCtx.beginPath();
            voiceCtx.arc(x, y, size, 0, Math.PI * 2);
            voiceCtx.fill();
            
            // Microphone circle
            voiceCtx.strokeStyle = isListening ? '#ffffff' : 'rgba(255, 255, 255, 0.8)';
            voiceCtx.lineWidth = 4;
            voiceCtx.beginPath();
            voiceCtx.arc(x, y, size * 0.5, 0, Math.PI * 2);
            voiceCtx.stroke();
            
            // Microphone body (rectangle)
            voiceCtx.fillStyle = isListening ? '#ffffff' : 'rgba(255, 255, 255, 0.9)';
            voiceCtx.fillRect(bodyX, bodyY, bodyWidth, bodyHeight);
            
            // Microphone stand
            const standWidth = size * 0.15;
            const standHeight = size * 0.3;
            voiceCtx.fillRect(x - standWidth / 2, y + bodyHeight / 2, standWidth, standHeight);
            
            // Microphone base
            const baseWidth = size * 0.6;
            const baseHeight = size * 0.1;
            voiceCtx.fillRect(x - baseWidth / 2, y + bodyHeight / 2 + standHeight, baseWidth, baseHeight);
            
            voiceCtx.restore();
        }

        function drawRealTimeSoundWaves(centerX, centerY, width, height, audioData, averageVolume) {
            voiceCtx.save();
            
            // Draw circular frequency bars based on FFT data
            const numBars = Math.min(audioData.length, 128); // Limit to 128 bars for performance
            const barRadius = 120;
            const maxBarLength = 100;
            
            for (let i = 0; i < numBars; i++) {
                const angle = (i / numBars) * Math.PI * 2;
                const barX = centerX + Math.cos(angle) * barRadius;
                const barY = centerY + Math.sin(angle) * barRadius;
                
               
                const amplitude = audioData[i] / 255;
                const barLength = amplitude * maxBarLength;
                
                const endX = centerX + Math.cos(angle) * (barRadius + barLength);
                const endY = centerY + Math.sin(angle) * (barRadius + barLength);
                
                
                const hue = 340; // this is Red hue
                const saturation = 80 + amplitude * 20;
                const lightness = 40 + amplitude * 40;
                
                const barGradient = voiceCtx.createLinearGradient(barX, barY, endX, endY);
                barGradient.addColorStop(0, `hsla(${hue}, ${saturation}%, ${lightness}%, 0.8)`);
                barGradient.addColorStop(1, `hsla(${hue}, ${saturation}%, ${lightness + 20}%, 0.3)`);
                
                voiceCtx.strokeStyle = barGradient;
                voiceCtx.lineWidth = 4;
                voiceCtx.lineCap = 'round';
                voiceCtx.beginPath();
                voiceCtx.moveTo(barX, barY);
                voiceCtx.lineTo(endX, endY);
                voiceCtx.stroke();
            }
          
            const numWaves = 3;
            for (let wave = 0; wave < numWaves; wave++) {
                const baseRadius = 150 + wave * 50;
                const volumeEffect = (averageVolume / 255) * 30;
                const radius = baseRadius + volumeEffect + Math.sin(time * 2 + wave) * 10;
                const opacity = (0.4 - wave * 0.1) * (averageVolume / 255);
                
                const waveGradient = voiceCtx.createRadialGradient(
                    centerX, centerY, radius - 10,
                    centerX, centerY, radius + 10
                );
                waveGradient.addColorStop(0, `rgba(255, 26, 77, ${opacity})`);
                waveGradient.addColorStop(0.5, `rgba(140, 10, 34, ${opacity * 0.7})`);
                waveGradient.addColorStop(1, `rgba(140, 10, 34, 0)`);
                
                voiceCtx.strokeStyle = waveGradient;
                voiceCtx.lineWidth = 3;
                voiceCtx.beginPath();
                voiceCtx.arc(centerX, centerY, radius, 0, Math.PI * 2);
                voiceCtx.stroke();
            }
            
            // Draw frequency spectrum as waveform
            voiceCtx.beginPath();
            voiceCtx.lineWidth = 3;
            voiceCtx.strokeStyle = 'rgba(255, 255, 255, 0.6)';
            
            const waveformRadius = 80;
            const samplesPerSegment = Math.floor(audioData.length / 64);
            
            for (let i = 0; i < 64; i++) {
                const angle = (i / 64) * Math.PI * 2;
                
               
                let sum = 0;
                for (let j = 0; j < samplesPerSegment; j++) {
                    const index = i * samplesPerSegment + j;
                    if (index < audioData.length) {
                        sum += audioData[index];
                    }
                }
                const avgAmplitude = (sum / samplesPerSegment) / 255;
                
                const radius = waveformRadius + avgAmplitude * 40;
                const x = centerX + Math.cos(angle) * radius;
                const y = centerY + Math.sin(angle) * radius;
                
                if (i === 0) {
                    voiceCtx.moveTo(x, y);
                } else {
                    voiceCtx.lineTo(x, y);
                }
            }
            
            voiceCtx.closePath();
            voiceCtx.stroke();
            
            voiceCtx.restore();
        }

        async function toggleVoiceRecognition() {
            const btn = document.getElementById('startVoiceBtn');
            
            if (!isListening) {
                // Start listening
                btn.disabled = true;
                btn.textContent = 'Initializing...';
                
                const success = await startMicrophoneCapture();
                
                if (success) {
                    isListening = true;
                    btn.textContent = 'Stop Listening';
                    btn.classList.add('active');
                } else {
                    btn.textContent = 'Start Listening';
                }
                
                btn.disabled = false;
            } else {
                // Stop listening
                isListening = false;
                stopMicrophoneCapture();
                btn.textContent = 'Start Listening';
                btn.classList.remove('active');
            }
        }
        
        // Create stars when page loads
        createStars();
    </script>
</body>
</html>
